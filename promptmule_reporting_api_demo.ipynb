{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9RscsxSXH75uQkfIxPkwS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/promptmule4real/demo/blob/main/promptmule_reporting_api_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# PromptMule Reporting API Demo v0.2\n",
        "\n",
        "Welcome to our interactive demonstration. Utilizing the PromptMule cache not only facilitates automatic caching of prompts and responses to OpenAI but also eliminates the need for personal management of these tasks. Stored securely in the AWS Cloud, this data can be conveniently downloaded via the Report API whenever you wish. To begin with, let's generate some traffic through a few prompts and subsequently, some reports.\n",
        "\n",
        "This guide will direct you through the process of effectively using the Reporting API, empowering you to fully leverage the benefits of the PromptMule reporting service. Specifically designed for the Google Colaboratory runtime environment, this demo guides you through sending reports via OpenAI and testing the reporting functions. If you don't already have an API Key or Token, refer to our GitHub guide to generate these here: [https://github.com/promptmule4real/demo/blob/main/promptmule_api_demo.ipynb]\n",
        "\n",
        "If you're viewing this on GitHub (https://github.com/), click the \"Open in Colab\" button, located in the upper left corner of the GitHub Preview page. This will launch the Google Colab notebook in a new tab, providing you the opportunity to run, modify, and interact with the demo code.\n",
        "\n",
        "After launching the notebook in Google Colab, follow the subsequent instructions outlined below to make effective use of the PromptMule Reporting API.\n",
        "\n",
        "Please note that a more in-depth demo of additional PromptMule capabilities is scheduled to be released at the conclusion of our next development sprint!\n",
        "\n",
        "We warmly welcome you to immerse yourself in this interactive experience and appreciate any feedback or queries you may have. Reach out to us at www.promptmule.com.\n",
        "\n",
        "---\n",
        "\n",
        "If you're currently in Google Colab (https://colab.research.google.com/): To begin, click on the \"Run Cell\" button located to the left of the code block. Resembling a play button on a media player, activating this will enable you to explore and experiment with the code at your leisure."
      ],
      "metadata": {
        "id": "PJvAGfifZh92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install DeepDiff"
      ],
      "metadata": {
        "id": "X_Pz2I5LRH9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB8C5yR6Zcd3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "import textwrap\n",
        "from deepdiff import DeepDiff"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Input your PromptMule Sign-in Attributes { run: \"auto\", display-mode: \"both\" }\n",
        "#@markdown Below replace the capital LETTERS with your information, pick a username, complex password, real email, and an application name that you will use as a reference in the future.\n",
        "\n",
        "your_username = \"YOUR_USERNAME\"  #@param {type: \"string\"}  # this is your username, it will need to be unique, else the API will tell you it's not and try again (str)\n",
        "api_key = \"YOUR_PROMPTMULE_API_KEY\"    #@param {type: \"string\"} # complex passwords are required (str)\n",
        "your_appname = \"YOUR_APPNAME\"    #@param {type: \"string\"}   # this is the application that you are using the promptmule API to build, this app name is unique (str)\n",
        "api_token = \"YOUR_PROMPTMULE_TOKEN\"    #@param {type: \"string\"}   # this is the application that you are using the promptmule API to build, this app name is unique (str)\n",
        "#@markdown ---"
      ],
      "metadata": {
        "id": "akXjrPniZ4bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Input OpenAI API KEY { run: \"auto\", display-mode: \"form\" }\n",
        "#@markdown Input your OpenAI API key here. To obtain an OpenAI API key (https://platform.openai.com/account/api-keys), OR sign up on the OpenAI website, provide necessary information, and upon approval, you'll be issued an API key to authenticate your requests to the API.\n",
        "\n",
        "OPENAI_API_KEY = 'YOUR_OPENAI_API_KEY' #@param {type: \"string\"} # this is your OpenAI API Key, it may impact your model choice\n",
        "#@markdown ---\n"
      ],
      "metadata": {
        "id": "XnO543JMePAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PromptMule's /prompt endpoint API\n",
        "\n",
        "Using the PromptMule cache enables you to automatically cache prompts and responses to OpenAI, without having to manage those yourself. These will be kept in the AWS Cloud until you wish to download them via a the Report API. First, you will need to generate some traffic with a few prompts.\n",
        "\n",
        "You can utilize the /prompt endpoint using your PromptMule Token and API key, along with your OPENAI_API_KEY. These can be used to interact, via the PromptMule cache, with GPT-4 and/or GPT-3.5 models via the chat completion endpoint of OpenAI, available at: https://api.openai.com/v1/chat/completions\n",
        "\n",
        "For information on how to structure the OpenAI Request Body, refer to the official documentation here: https://platform.openai.com/docs/api-reference/chat/create\n",
        "\n",
        "We have incorporated some unique parameters specific to `promptmule`:\n",
        "\n",
        "- `api` (String): A required field, for this demonstration use \"openai\" which is the only supported API currently.\n",
        "\n",
        "- `semantic` (Float): This required parameter specifies the \"percentage match\" of the sent prompt with existing prompts in the cache. If a match is found with a percentage equal to or higher than this value, a maximum number of matches (as defined by `sem_num`) will be returned in a JSON dictionary.\n",
        "\n",
        "- `sem_num` (Integer): A required parameter which should be a number between 1 and 10. It represents the maximum number of semantic matches to be found in the cache and returned in the API response as a JSON dictionary."
      ],
      "metadata": {
        "id": "kxANfUF_a21f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to update the headers for the Prompt API call, per below with Authorization which is different than previous calls using your API Token, and x-api-key which is your PromptMule API-Key, and your OpenAI API-Key."
      ],
      "metadata": {
        "id": "00w4v1WP982n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ENDPOINT = 'https://820czjhki0.execute-api.us-west-2.amazonaws.com/dev/'\n",
        "PROMPT = 'prompt'\n",
        "\n",
        "headers = {           # this is the /prompt endpoint header\n",
        "    'Authorization': api_token,\n",
        "    'x-api-key': api_key,\n",
        "    'openai-key': OPENAI_API_KEY,\n",
        "    'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "api_call_body = {     # this is a /prompt call body example\n",
        "    \"model\": \"gpt-4-0613\",  # using GPT-4, you must have access to this model, or the call will fail\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Create a Psuedocode function for the chances of seeing a unicorn in Central Park. Assume the probability is the square root of -1.\"\n",
        "        }\n",
        "    ],\n",
        "    \"max_tokens\": \"100\",\n",
        "    \"temperature\": \"0.99\",\n",
        "    \"top_p\": \"1\",\n",
        "    \"n\": \"1\",\n",
        "    \"logprobs\": \"null\",\n",
        "    \"stop\": \"null\",\n",
        "    \"suffix\": \"null\",\n",
        "    \"echo\": \"true\",\n",
        "    \"presence_penalty\": \"0\",\n",
        "    \"frequency_penalty\": \"0\",\n",
        "    \"best_of\": \"1\",\n",
        "    \"logit_bias\": \"null\",\n",
        "    \"user\": your_username,\n",
        "    \"api\": \"openai\",    # this is used to denote openai as the destination\n",
        "    \"semantic\": \"0.99\", # this denotes the semantic match percentage in the cache\n",
        "    \"sem_num\": \"2\"      # this denotes the number of matches to return if found\n",
        "}"
      ],
      "metadata": {
        "id": "GFSOWfxM9rZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we are pointing the endpoint at the Prompt endpoint this time, and then sending the API call."
      ],
      "metadata": {
        "id": "XYq6BnHs-C9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "promptmule = ENDPOINT + PROMPT\n",
        "promptmule_response = requests.request(\"POST\", promptmule, headers=headers, json=api_call_body)\n",
        "# Handle response\n",
        "if promptmule_response.status_code == 200:\n",
        "    print(\"Response from OpenAI successful:\\n\", json.dumps(json.loads(promptmule_response.text), indent=4))\n",
        "else:\n",
        "    print(f\"Response from OpenAI failed with status code {promptmule_response.status_code}:\\n\", json.dumps(json.loads(promptmule_response.text), indent=4))"
      ],
      "metadata": {
        "id": "BKcoMTdu-I_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's Poke the Cache 10 Time\n",
        "poke = 10\n",
        "# If you only want to see the diff's of the returned response for each call set diff_only to True\n",
        "diff_only = True\n",
        "i = 0 # used to count iterations\n",
        "# Run the loop 10 times\n",
        "for _ in range(poke):\n",
        "    try:\n",
        "        print(\"Sending iteration: #\", i)\n",
        "        i = i + 1;\n",
        "        promptmule_repeated_response = requests.post(promptmule, headers=headers, json=api_call_body)\n",
        "        response_json = json.loads(promptmule_response.text)\n",
        "        diff = DeepDiff(promptmule_response, promptmule_repeated_response, ignore_order=True)\n",
        "        # Handle response\n",
        "        if promptmule_response.status_code == 200:\n",
        "            if not diff_only:\n",
        "              print(\"Response from PromptMule API successful:\\n\", json.dumps(response_json, indent=4))\n",
        "            else:\n",
        "              print(\"This diff between the first API call through PromptMule, and this call through PromptMule:\", diff)\n",
        "        elif promptmule_response.status_code == 400:\n",
        "            print(f\"Bad request. Details: {response_json}\")\n",
        "        elif promptmule_response.status_code == 500:\n",
        "            print(f\"Runtime Service Exception. Details: {response_json}\")\n",
        "        else:\n",
        "            print(f\"Unexpected status code {promptmule_response.status_code}. Details: {response_json}\")\n",
        "\n",
        "    except requests.exceptions.HTTPError as errh:\n",
        "        print(f\"Http Error:{errh}\")\n",
        "\n",
        "    except requests.exceptions.ConnectionError as errc:\n",
        "        print(f\"Error Connecting:{errc}\")\n",
        "\n",
        "    except requests.exceptions.Timeout as errt:\n",
        "        print(f\"Timeout Error:{errt}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as err:\n",
        "        print(f\"Something went wrong with the request:{err}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "9LuPvvj_DWC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the Application Use Report API based on a user's API KEY\n",
        "USAGE = \"usage\" # this is the Applicaton Use Report endpoint\n",
        "\n",
        "headers = {           # this is the /usage endpoint header\n",
        "    'Authorization': api_token,\n",
        "    'x-api-key': api_key,\n",
        "    'Content-Type': 'application/json'\n",
        "    }\n"
      ],
      "metadata": {
        "id": "1Ri02-PIDaBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the Application Usage Report for this API KEY\n",
        "promptmule = ENDPOINT + USAGE\n",
        "\n",
        "try:\n",
        "    promptmule_response = requests.get(promptmule, headers=headers)\n",
        "    response_json = json.loads(promptmule_response.text)\n",
        "\n",
        "    # Handle response\n",
        "    if promptmule_response.status_code == 200:\n",
        "        print(\"Response from PromptMule API successful:\\n\", json.dumps(response_json, indent=4))\n",
        "    elif promptmule_response.status_code == 400:\n",
        "        print(f\"Bad request. Details: {response_json}\")\n",
        "    elif promptmule_response.status_code == 500:\n",
        "        print(f\"Runtime Service Exception. Details: {response_json}\")\n",
        "    else:\n",
        "        print(f\"Unexpected status code {promptmule_response.status_code}. Details: {response_json}\")\n",
        "\n",
        "except requests.exceptions.HTTPError as errh:\n",
        "    print(f\"Http Error:{errh}\")\n",
        "\n",
        "except requests.exceptions.ConnectionError as errc:\n",
        "    print(f\"Error Connecting:{errc}\")\n",
        "\n",
        "except requests.exceptions.Timeout as errt:\n",
        "    print(f\"Timeout Error:{errt}\")\n",
        "\n",
        "except requests.exceptions.RequestException as err:\n",
        "    print(f\"Something went wrong with the request:{err}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "FqJwHBCOGQAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the header setup for the Application Use Report API based on a user's API KEY\n",
        "DATE_RANGE_REPORT = \"usage/daily-stats\" # this is the Applicaton Use Report endpoint\n",
        "\n",
        "headers = {           # this is the /usage endpoint header\n",
        "    'Authorization': api_token,\n",
        "    'x-api-key': api_key,\n",
        "    'Content-Type': 'application/json'\n",
        "    }"
      ],
      "metadata": {
        "id": "i5RQsclRIRgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Date Range Report for Application per API KEY\n",
        "# set the Application Use Reporting endpoint\n",
        "promptmule = ENDPOINT + DATE_RANGE_REPORT\n",
        "try:\n",
        "    promptmule_response = requests.get(promptmule, headers=headers)\n",
        "    response_json = json.loads(promptmule_response.text)\n",
        "\n",
        "    # Handle response\n",
        "    if promptmule_response.status_code == 200:\n",
        "        print(\"Response from PromptMule API successful:\\n\", json.dumps(response_json, indent=4))\n",
        "    elif promptmule_response.status_code == 400:\n",
        "        print(f\"Bad request. Details: {response_json}\")\n",
        "    elif promptmule_response.status_code == 500:\n",
        "        print(f\"Runtime Service Exception. Details: {response_json}\")\n",
        "    else:\n",
        "        print(f\"Unexpected status code {promptmule_response.status_code}. Details: {response_json}\")\n",
        "\n",
        "except requests.exceptions.HTTPError as errh:\n",
        "    print(f\"Http Error:{errh}\")\n",
        "\n",
        "except requests.exceptions.ConnectionError as errc:\n",
        "    print(f\"Error Connecting:{errc}\")\n",
        "\n",
        "except requests.exceptions.Timeout as errt:\n",
        "    print(f\"Timeout Error:{errt}\")\n",
        "\n",
        "except requests.exceptions.RequestException as err:\n",
        "    print(f\"Something went wrong with the request:{err}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "BDUKILGpHr8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retreive all API Keys for a username"
      ],
      "metadata": {
        "id": "z-uRv0S8LrJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the header setup for the Get All User API Keys\n",
        "GET_ALL_API_KEYS_PER_USER = \"api-keys\" # this is the Get ALL User API Keys endpoint\n",
        "\n",
        "headers = {           # this is the GET /api-keys endpoint header\n",
        "    'Authorization': api_token,\n",
        "    'Content-Type': 'application/json'\n",
        "    }"
      ],
      "metadata": {
        "id": "un0JjnHbMST8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Date Range Report for Application per API KEY\n",
        "# set the Get All Keys Reporting endpoint\n",
        "promptmule = ENDPOINT + GET_ALL_API_KEYS_PER_USER\n",
        "try:\n",
        "    promptmule_response = requests.get(promptmule, headers=headers)\n",
        "    response_json = json.loads(promptmule_response.text)\n",
        "\n",
        "    # Handle response\n",
        "    if promptmule_response.status_code == 200:\n",
        "        print(\"Get All Keys for Users successful:\\n\", json.dumps(response_json, indent=4))\n",
        "    elif promptmule_response.status_code == 400:\n",
        "        print(f\"Bad request. Details: {response_json}\")\n",
        "    elif promptmule_response.status_code == 500:\n",
        "        print(f\"Runtime Service Exception. Details: {response_json}\")\n",
        "    else:\n",
        "        print(f\"Unexpected status code {promptmule_response.status_code}. Details: {response_json}\")\n",
        "\n",
        "except requests.exceptions.HTTPError as errh:\n",
        "    print(f\"Http Error:{errh}\")\n",
        "\n",
        "except requests.exceptions.ConnectionError as errc:\n",
        "    print(f\"Error Connecting:{errc}\")\n",
        "\n",
        "except requests.exceptions.Timeout as errt:\n",
        "    print(f\"Timeout Error:{errt}\")\n",
        "\n",
        "except requests.exceptions.RequestException as err:\n",
        "    print(f\"Something went wrong with the request:{err}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "ZQOuYzPeLkEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the header setup for the Get All User Prompts\n",
        "PROMPT = \"prompt\" # this is the Get ALL User API Keys endpoint\n",
        "\n",
        "headers = {           # this is the GET /api-keys endpoint header\n",
        "    'Authorization': api_token,\n",
        "    'x-api-key': api_key,\n",
        "    'Content-Type': 'application/json',\n",
        "    'Credential': '', # Bug?\n",
        "    'Signature': '',\n",
        "    'SignedHeaders': '',\n",
        "    'Date': ''\n",
        "    }\n",
        "# NOTE the use of parameters here to convey the start date of the prompts you want to retrieve and the end date. Also, you can choose to ask for prompts that have been cached or not, this is done with the \"is_cached\" parameter, where 'TRUE' means that the values will be returned form the live cache, and 'FALSE' returns any prompt that has occured between the two dates. Finally, 'limit' is the maximum number (int) between 1 and 100 of the prompts to return in the reply json.\n",
        "params = {\n",
        "    'start-date': '2023-07-01', # First Date to begin Search for Prompts\n",
        "    'end-date': '2023-07-27', # Date to end Search for Prompts\n",
        "    'is-cached': 'False', # Whether or not to include Cache in Search\n",
        "    'limit': '10' # The Maximum number of Prompt/Respons pairs to return\n",
        "}"
      ],
      "metadata": {
        "id": "FY_Ru0ljNdDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Prompt/Response Report for a Date Rannge\n",
        "# set the Prompt/Response endpoint\n",
        "promptmule = ENDPOINT + PROMPT\n",
        "\n",
        "try:\n",
        "    promptmule_response = requests.get(ENDPOINT, headers=headers, params=params)\n",
        "    response_json = json.loads(promptmule_response.text)\n",
        "\n",
        "    # Handle response\n",
        "    if promptmule_response.status_code == 200:\n",
        "        print(\"The prompts were found successfully:\\n\", json.dumps(response_json, indent=4))\n",
        "    elif promptmule_response.status_code == 400:\n",
        "        print(f\"Bad request. Details: {response_json}\")\n",
        "    elif promptmule_response.status_code == 500:\n",
        "        print(f\"Runtime Service Exception. Details: {response_json}\")\n",
        "    else:\n",
        "        print(f\"Unexpected status code {promptmule_response.status_code}. Details: {response_json}\")\n",
        "\n",
        "except requests.exceptions.HTTPError as errh:\n",
        "    print(f\"Http Error:{errh}\")\n",
        "\n",
        "except requests.exceptions.ConnectionError as errc:\n",
        "    print(f\"Error Connecting:{errc}\")\n",
        "\n",
        "except requests.exceptions.Timeout as errt:\n",
        "    print(f\"Timeout Error:{errt}\")\n",
        "\n",
        "except requests.exceptions.RequestException as err:\n",
        "    print(f\"Something went wrong with the request:{err}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "hpiRoukTN0jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Congratulations! You have are one of us now!\n",
        "That's the end of this demo. Let us know what you think."
      ],
      "metadata": {
        "id": "Jxum3sSiAlYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Errors in Colab or PromptMule API\n",
        "\n",
        "In the course of running the demo, should you encounter any errors or issues, the Colab environment provides you with features to debug and resolve them.\n",
        "\n",
        "1. **Runtime Reset**: If your notebook's runtime seems stuck or producing unexpected errors, you can reset it by selecting 'Runtime > Restart runtime...' from the menu.\n",
        "\n",
        "2. **Check Error Logs**: Colab provides detailed error logs for each cell. If a cell execution fails, you will see an error message below the cell which can provide clues on what went wrong.\n",
        "\n",
        "3. **PromptMule Support can reset your username**: And your email/passwrod/Token/Key if needed. Reach out to us and join our private preview slack at support@promptmule.com"
      ],
      "metadata": {
        "id": "tkEmlyrZLwHa"
      }
    }
  ]
}