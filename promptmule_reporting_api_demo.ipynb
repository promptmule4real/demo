{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIizARhDDZY1e1ir3TWRuG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/promptmule4real/demo/blob/main/promptmule_reporting_api_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PromptMule Reporting API Demo v0.1\n",
        "\n",
        "Welcome to our interactive demonstration guide. Using the PromptMule cache enables you to automatically cache prompts and responses to OpenAI, without having to manage those yourself. These will be kept in the AWS Cloud until you wish to download them via a the Report API. First, you will need to generate some traffic with a few prompts, then some reports.\n",
        "\n",
        "This tutorial will guide you through the process of using the Reporting API, enabling you to harness the full potential of the PromptMule reporting service. Tailored specifically for a Google Colaboratory runtime environment, this demo provides an engaging exploration into sending reports through OpenAI and testing reporting functions. If you do not have an API-KEY or Token, see the Github guide to generate those here:[https://github.com/promptmule4real/demo/blob/main/promptmule_api_demo.ipynb]\n",
        "\n",
        "If you are reading this while on Github(https://github.com/): Start by clicking the \"Open in Colab\" icon located at the top left corner of the Github Preview page. This action will open the Google Colab notebook in a new tab, giving you the ability to run, modify, and interact with the demo code within.\n",
        "\n",
        "Once you've launched the notebook in Google Colab, follow the subsequent step-by-step instructions below to effectively use the PromptMule Reporting API.\n",
        "\n",
        "Stay tuned for a more comprehensive demo of other PromptMule functionalities, set to debut at the end of our next sprint!\n",
        "\n",
        "We invite you to dive into this interactive exploration, and welcome your participation and feedback. Please visit us at www.promptmule.com.\n",
        "\n",
        "If you are reading this while in Google Colab(https://colab.research.google.com/): To start, simply click on the \"Run Cell\" button located to the left of the code block. It resembles the play button you might find on a media player. Once activated, feel free to explore and experiment with the code."
      ],
      "metadata": {
        "id": "PJvAGfifZh92"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB8C5yR6Zcd3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ENDPOINT = 'https://820czjhki0.execute-api.us-west-2.amazonaws.com/dev/'\n",
        "REGISTRATION = 'dev-signup' # registration for a developer\n",
        "LOGIN = 'login'\n",
        "KEY_GEN = 'api-keys'\n",
        "PROMPT = 'prompt'"
      ],
      "metadata": {
        "id": "JaOtrKNnZwsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Form to update python variables\n",
        "#@markdown Below replace the capital LETTERS with your information, pick a username, complex password, real email, and an application name that you will use as a reference in the future.\n",
        "\n",
        "your_new_username = \"YOUR_NEW_USERNAME\"  #@param {type: \"string\"}  # this is your username, it will need to be unique, else the API will tell you it's not and try again (str)\n",
        "your_new_password = \"YOUR_PASSWORD\"    #@param {type: \"string\"} # complex passwords are required (str)\n",
        "your_same_old_email = \"YOUR_EMAIL\" #@param {type: \"string\"} # must be a valid email as it is used in this process to validate (str)\n",
        "your_new_appname = \"YOUR_APPNAME\"    #@param {type: \"string\"}   # this is the application that you are using the promptmule API to build, this app name is unique (str)\n",
        "#@markdown ---\n"
      ],
      "metadata": {
        "id": "akXjrPniZ4bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PromptMule's /prompt endpoint API\n",
        "\n",
        "Using the PromptMule cache enables you to automatically cache prompts and responses to OpenAI, without having to manage those yourself. These will be kept in the AWS Cloud until you wish to download them via a the Report API. First, you will need to generate some traffic with a few prompts.\n",
        "\n",
        "You can utilize the /prompt endpoint using your PromptMule Token and API key, along with your OPENAI_API_KEY. These can be used to interact, via the PromptMule cache, with GPT-4 and/or GPT-3.5 models via the chat completion endpoint of OpenAI, available at: https://api.openai.com/v1/chat/completions\n",
        "\n",
        "For information on how to structure the OpenAI Request Body, refer to the official documentation here: https://platform.openai.com/docs/api-reference/chat/create\n",
        "\n",
        "We have incorporated some unique parameters specific to `promptmule`:\n",
        "\n",
        "- `api` (String): A required field, for this demonstration use \"openai\" which is the only supported API currently.\n",
        "\n",
        "- `semantic` (Float): This required parameter specifies the \"percentage match\" of the sent prompt with existing prompts in the cache. If a match is found with a percentage equal to or higher than this value, a maximum number of matches (as defined by `sem_num`) will be returned in a JSON dictionary.\n",
        "\n",
        "- `sem_num` (Integer): A required parameter which should be a number between 1 and 10. It represents the maximum number of semantic matches to be found in the cache and returned in the API response as a JSON dictionary."
      ],
      "metadata": {
        "id": "kxANfUF_a21f"
      }
    }
  ]
}